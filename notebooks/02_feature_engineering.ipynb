{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 02 - Feature Engineering\n",
    "\n",
    "This notebook performs feature engineering for the maternal health risk prediction model.\n",
    "\n",
    "## Objectives\n",
    "1. Handle missing values with appropriate imputation strategies\n",
    "2. Encode categorical variables for machine learning\n",
    "3. Create derived features (interactions, bins, polynomial)\n",
    "4. Build feature sets for model training\n",
    "5. Save processed data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler,\n",
    "    OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data_loader import (\n",
    "    create_high_risk_indicator,\n",
    "    create_demographic_groups\n",
    ")\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We recreate the synthetic demonstration dataset from notebook 01. In production, load the actual DHS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, create synthetic data matching DHS structure\n",
    "# In production: df = pd.read_csv('../data/processed/maternal_health_combined.csv')\n",
    "\n",
    "print(\"Creating synthetic demonstration data...\")\n",
    "print(\"(Replace with actual DHS data loading when files are available)\\n\")\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "\n",
    "# Base features\n",
    "df = pd.DataFrame({\n",
    "    'country': np.random.choice(['NG', 'KE', 'GH', 'UG', 'TZ'], n_samples, p=[0.35, 0.2, 0.15, 0.15, 0.15]),\n",
    "    'age': np.random.normal(28, 7, n_samples).clip(15, 49).astype(int),\n",
    "    'residence_type': np.random.choice([1, 2], n_samples, p=[0.35, 0.65]),\n",
    "    'education_level': np.random.choice([0, 1, 2, 3], n_samples, p=[0.15, 0.35, 0.35, 0.15]),\n",
    "    'wealth_index': np.random.choice([1, 2, 3, 4, 5], n_samples),\n",
    "    'total_children_born': np.random.poisson(2.5, n_samples),\n",
    "    'anemia_level': np.random.choice([1, 2, 3, 4], n_samples, p=[0.05, 0.15, 0.25, 0.55]),\n",
    "    'birth_interval_months': np.random.exponential(30, n_samples).astype(int),\n",
    "    'antenatal_visits': np.random.poisson(4, n_samples).clip(0, 15),\n",
    "    'bmi': np.random.normal(24, 5, n_samples).clip(15, 45),\n",
    "    'distance_health_facility_problem': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),\n",
    "    'health_insurance': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),\n",
    "    'pregnancy_terminated': np.random.choice([0, 1], n_samples, p=[0.85, 0.15]),\n",
    "    'region': np.random.randint(1, 8, n_samples),\n",
    "})\n",
    "\n",
    "# Introduce realistic missing values\n",
    "missing_rates = {\n",
    "    'birth_interval_months': 0.15,  # Missing for first births\n",
    "    'anemia_level': 0.10,           # Not all tested\n",
    "    'bmi': 0.08,                    # Not all measured\n",
    "    'antenatal_visits': 0.05,       # Some missing\n",
    "    'health_insurance': 0.03,       # Some unknown\n",
    "}\n",
    "\n",
    "for col, rate in missing_rates.items():\n",
    "    missing_mask = np.random.random(n_samples) < rate\n",
    "    df.loc[missing_mask, col] = np.nan\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Assess Missing Values\n",
    "\n",
    "Understanding missing data patterns is critical for choosing appropriate imputation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing value statistics\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Missing Count': df.isnull().sum(),\n",
    "    'Missing %': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Data Type': df.dtypes\n",
    "})\n",
    "missing_stats = missing_stats[missing_stats['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"Missing Value Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(missing_stats)\n",
    "print(f\"\\nTotal rows: {len(df):,}\")\n",
    "print(f\"Complete cases: {df.dropna().shape[0]:,} ({df.dropna().shape[0]/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data patterns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Missing value counts\n",
    "if len(missing_stats) > 0:\n",
    "    missing_stats['Missing %'].plot(kind='barh', ax=axes[0], color='coral')\n",
    "    axes[0].set_xlabel('Missing Percentage')\n",
    "    axes[0].set_title('Missing Values by Feature')\n",
    "    axes[0].axvline(x=5, color='red', linestyle='--', alpha=0.7, label='5% threshold')\n",
    "    axes[0].legend()\n",
    "else:\n",
    "    axes[0].text(0.5, 0.5, 'No missing values', ha='center', va='center', fontsize=14)\n",
    "    axes[0].set_title('Missing Values by Feature')\n",
    "\n",
    "# Missing data heatmap (sample)\n",
    "sample_df = df.sample(min(100, len(df)), random_state=42)\n",
    "sns.heatmap(sample_df.isnull(), cbar=True, yticklabels=False, ax=axes[1], cmap='viridis')\n",
    "axes[1].set_title('Missing Data Pattern (Sample of 100 rows)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/missing_values_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Handle Missing Values\n",
    "\n",
    "We apply different imputation strategies based on variable type and missingness pattern:\n",
    "\n",
    "| Strategy | Use Case |\n",
    "|----------|----------|\n",
    "| Median | Skewed numeric variables |\n",
    "| Mean | Normally distributed numeric variables |\n",
    "| Mode | Categorical variables |\n",
    "| KNN | Complex patterns with multiple missing |\n",
    "| Indicator | When missingness is informative |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for imputation\n",
    "df_imputed = df.copy()\n",
    "\n",
    "# Define imputation strategies by variable\n",
    "imputation_strategies = {\n",
    "    # Numeric - use median for robustness to outliers\n",
    "    'birth_interval_months': 'median',\n",
    "    'bmi': 'median',\n",
    "    'antenatal_visits': 'median',\n",
    "    \n",
    "    # Categorical/ordinal - use mode\n",
    "    'anemia_level': 'mode',\n",
    "    'health_insurance': 'mode',\n",
    "}\n",
    "\n",
    "# Create missing indicators for variables where missingness may be informative\n",
    "informative_missing = ['birth_interval_months', 'anemia_level']\n",
    "\n",
    "for col in informative_missing:\n",
    "    if col in df_imputed.columns:\n",
    "        df_imputed[f'{col}_missing'] = df_imputed[col].isnull().astype(int)\n",
    "\n",
    "print(\"Created missing indicators for:\")\n",
    "print(informative_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply imputation\n",
    "for col, strategy in imputation_strategies.items():\n",
    "    if col not in df_imputed.columns:\n",
    "        continue\n",
    "        \n",
    "    missing_count = df_imputed[col].isnull().sum()\n",
    "    if missing_count == 0:\n",
    "        continue\n",
    "    \n",
    "    if strategy == 'median':\n",
    "        fill_value = df_imputed[col].median()\n",
    "    elif strategy == 'mean':\n",
    "        fill_value = df_imputed[col].mean()\n",
    "    elif strategy == 'mode':\n",
    "        fill_value = df_imputed[col].mode()[0]\n",
    "    else:\n",
    "        fill_value = strategy  # Use provided value\n",
    "    \n",
    "    df_imputed[col] = df_imputed[col].fillna(fill_value)\n",
    "    print(f\"{col}: imputed {missing_count} values with {strategy} ({fill_value:.2f})\")\n",
    "\n",
    "# Verify no missing values remain in key columns\n",
    "print(f\"\\nRemaining missing values: {df_imputed[list(imputation_strategies.keys())].isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Variables\n",
    "\n",
    "We use different encoding strategies based on variable type:\n",
    "\n",
    "- **Ordinal Encoding**: For ordered categories (education level, wealth index)\n",
    "- **One-Hot Encoding**: For nominal categories (country, residence)\n",
    "- **Binary Encoding**: For binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable types\n",
    "ordinal_vars = {\n",
    "    'education_level': [0, 1, 2, 3],  # None < Primary < Secondary < Higher\n",
    "    'wealth_index': [1, 2, 3, 4, 5],   # Poorest to Richest\n",
    "    'anemia_level': [1, 2, 3, 4],      # Severe < Moderate < Mild < Not anemic\n",
    "}\n",
    "\n",
    "nominal_vars = ['country']  # No natural ordering\n",
    "\n",
    "binary_vars = ['residence_type', 'distance_health_facility_problem', \n",
    "               'health_insurance', 'pregnancy_terminated']\n",
    "\n",
    "print(\"Variable categorization:\")\n",
    "print(f\"  Ordinal: {list(ordinal_vars.keys())}\")\n",
    "print(f\"  Nominal: {nominal_vars}\")\n",
    "print(f\"  Binary: {binary_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for nominal variables\n",
    "for col in nominal_vars:\n",
    "    if col in df_imputed.columns:\n",
    "        dummies = pd.get_dummies(df_imputed[col], prefix=col, drop_first=False)\n",
    "        df_imputed = pd.concat([df_imputed, dummies], axis=1)\n",
    "        print(f\"One-hot encoded {col}: created {len(dummies.columns)} columns\")\n",
    "        print(f\"  Columns: {list(dummies.columns)}\")\n",
    "\n",
    "print(f\"\\nDataset shape after one-hot encoding: {df_imputed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create readable labels for demographic analysis\n",
    "df_imputed = create_demographic_groups(df_imputed)\n",
    "\n",
    "# Create binary encodings (already numeric but ensure proper coding)\n",
    "binary_mappings = {\n",
    "    'residence_type': {1: 0, 2: 1},  # 0=Urban, 1=Rural\n",
    "}\n",
    "\n",
    "for col, mapping in binary_mappings.items():\n",
    "    if col in df_imputed.columns:\n",
    "        df_imputed[f'{col}_encoded'] = df_imputed[col].map(mapping)\n",
    "        print(f\"Created {col}_encoded with mapping {mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Create Derived Features\n",
    "\n",
    "Engineering new features that may capture important risk patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age-related features\n",
    "df_imputed['age_squared'] = df_imputed['age'] ** 2\n",
    "df_imputed['age_risk_young'] = (df_imputed['age'] < 18).astype(int)\n",
    "df_imputed['age_risk_old'] = (df_imputed['age'] > 35).astype(int)\n",
    "df_imputed['age_risk_any'] = (df_imputed['age_risk_young'] | df_imputed['age_risk_old']).astype(int)\n",
    "\n",
    "# Age groups for analysis\n",
    "df_imputed['age_group'] = pd.cut(\n",
    "    df_imputed['age'], \n",
    "    bins=[14, 19, 24, 29, 34, 39, 50],\n",
    "    labels=['15-19', '20-24', '25-29', '30-34', '35-39', '40+']\n",
    ")\n",
    "\n",
    "print(\"Age-derived features created:\")\n",
    "print(\"  - age_squared: polynomial feature\")\n",
    "print(\"  - age_risk_young: <18 years indicator\")\n",
    "print(\"  - age_risk_old: >35 years indicator\")\n",
    "print(\"  - age_risk_any: combined age risk\")\n",
    "print(\"  - age_group: categorical age bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parity and birth interval features\n",
    "df_imputed['high_parity'] = (df_imputed['total_children_born'] > 4).astype(int)\n",
    "df_imputed['first_birth'] = (df_imputed['total_children_born'] == 0).astype(int)\n",
    "\n",
    "# Short birth interval (< 24 months)\n",
    "df_imputed['short_birth_interval'] = (df_imputed['birth_interval_months'] < 24).astype(int)\n",
    "\n",
    "# Parity groups\n",
    "df_imputed['parity_group'] = pd.cut(\n",
    "    df_imputed['total_children_born'],\n",
    "    bins=[-1, 0, 2, 4, 100],\n",
    "    labels=['0', '1-2', '3-4', '5+']\n",
    ")\n",
    "\n",
    "print(\"\\nParity features created:\")\n",
    "print(\"  - high_parity: >4 children indicator\")\n",
    "print(\"  - first_birth: first pregnancy indicator\")\n",
    "print(\"  - short_birth_interval: <24 months indicator\")\n",
    "print(\"  - parity_group: categorical parity bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health indicator features\n",
    "df_imputed['anemia_severe_moderate'] = df_imputed['anemia_level'].isin([1, 2]).astype(int)\n",
    "df_imputed['anemia_any'] = (df_imputed['anemia_level'] < 4).astype(int)\n",
    "\n",
    "# BMI categories (WHO classification)\n",
    "df_imputed['bmi_underweight'] = (df_imputed['bmi'] < 18.5).astype(int)\n",
    "df_imputed['bmi_overweight'] = (df_imputed['bmi'] >= 25).astype(int)\n",
    "df_imputed['bmi_obese'] = (df_imputed['bmi'] >= 30).astype(int)\n",
    "df_imputed['bmi_risk'] = (df_imputed['bmi_underweight'] | df_imputed['bmi_obese']).astype(int)\n",
    "\n",
    "df_imputed['bmi_category'] = pd.cut(\n",
    "    df_imputed['bmi'],\n",
    "    bins=[0, 18.5, 25, 30, 100],\n",
    "    labels=['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    ")\n",
    "\n",
    "print(\"\\nHealth indicator features created:\")\n",
    "print(\"  - anemia_severe_moderate: high-risk anemia\")\n",
    "print(\"  - anemia_any: any anemia present\")\n",
    "print(\"  - bmi_underweight, bmi_overweight, bmi_obese: BMI risk indicators\")\n",
    "print(\"  - bmi_risk: combined BMI risk (underweight or obese)\")\n",
    "print(\"  - bmi_category: WHO BMI classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Healthcare access features\n",
    "df_imputed['adequate_anc'] = (df_imputed['antenatal_visits'] >= 4).astype(int)  # WHO recommended minimum\n",
    "df_imputed['no_anc'] = (df_imputed['antenatal_visits'] == 0).astype(int)\n",
    "\n",
    "# Healthcare access composite\n",
    "df_imputed['healthcare_barriers'] = (\n",
    "    df_imputed['distance_health_facility_problem'] + \n",
    "    (1 - df_imputed['health_insurance'])\n",
    ").clip(0, 2)\n",
    "\n",
    "print(\"\\nHealthcare access features created:\")\n",
    "print(\"  - adequate_anc: >=4 ANC visits (WHO standard)\")\n",
    "print(\"  - no_anc: zero ANC visits\")\n",
    "print(\"  - healthcare_barriers: composite access barrier score (0-2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction features (socioeconomic with health)\n",
    "df_imputed['poor_rural'] = (\n",
    "    (df_imputed['wealth_index'] <= 2) & \n",
    "    (df_imputed['residence_type'] == 2)\n",
    ").astype(int)\n",
    "\n",
    "df_imputed['poor_uneducated'] = (\n",
    "    (df_imputed['wealth_index'] <= 2) & \n",
    "    (df_imputed['education_level'] <= 1)\n",
    ").astype(int)\n",
    "\n",
    "df_imputed['rural_no_insurance'] = (\n",
    "    (df_imputed['residence_type'] == 2) & \n",
    "    (df_imputed['health_insurance'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "df_imputed['young_high_parity'] = (\n",
    "    (df_imputed['age'] < 25) & \n",
    "    (df_imputed['total_children_born'] >= 3)\n",
    ").astype(int)\n",
    "\n",
    "# Cumulative vulnerability score\n",
    "df_imputed['vulnerability_score'] = (\n",
    "    (df_imputed['wealth_index'] <= 2).astype(int) +\n",
    "    (df_imputed['education_level'] <= 1).astype(int) +\n",
    "    (df_imputed['residence_type'] == 2).astype(int) +\n",
    "    df_imputed['distance_health_facility_problem'] +\n",
    "    (1 - df_imputed['health_insurance'])\n",
    ").astype(int)\n",
    "\n",
    "print(\"\\nInteraction features created:\")\n",
    "print(\"  - poor_rural: low wealth AND rural residence\")\n",
    "print(\"  - poor_uneducated: low wealth AND low education\")\n",
    "print(\"  - rural_no_insurance: rural AND uninsured\")\n",
    "print(\"  - young_high_parity: young mother with many children\")\n",
    "print(\"  - vulnerability_score: cumulative socioeconomic risk (0-5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 6. Create Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the high-risk pregnancy indicator\n",
    "df_imputed['high_risk'] = create_high_risk_indicator(df_imputed)\n",
    "\n",
    "print(\"Target variable distribution:\")\n",
    "print(df_imputed['high_risk'].value_counts(normalize=True).round(3))\n",
    "print(f\"\\nClass balance ratio: {df_imputed['high_risk'].mean():.2%} high-risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 7. Define Feature Sets\n",
    "\n",
    "Create organized feature sets for different modeling approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "FEATURE_SETS = {\n",
    "    # Core clinical features (minimal)\n",
    "    'clinical_minimal': [\n",
    "        'age', 'total_children_born', 'birth_interval_months',\n",
    "        'anemia_level', 'bmi', 'pregnancy_terminated'\n",
    "    ],\n",
    "    \n",
    "    # Extended clinical features\n",
    "    'clinical_extended': [\n",
    "        'age', 'age_squared', 'total_children_born', 'birth_interval_months',\n",
    "        'anemia_level', 'bmi', 'pregnancy_terminated', 'antenatal_visits',\n",
    "        'age_risk_any', 'high_parity', 'short_birth_interval',\n",
    "        'anemia_severe_moderate', 'bmi_risk', 'adequate_anc'\n",
    "    ],\n",
    "    \n",
    "    # Socioeconomic features\n",
    "    'socioeconomic': [\n",
    "        'wealth_index', 'education_level', 'residence_type_encoded',\n",
    "        'distance_health_facility_problem', 'health_insurance',\n",
    "        'healthcare_barriers', 'vulnerability_score'\n",
    "    ],\n",
    "    \n",
    "    # Full feature set (clinical + socioeconomic)\n",
    "    'full': [\n",
    "        # Demographics\n",
    "        'age', 'age_squared', 'residence_type_encoded',\n",
    "        'education_level', 'wealth_index',\n",
    "        \n",
    "        # Clinical\n",
    "        'total_children_born', 'birth_interval_months',\n",
    "        'anemia_level', 'bmi', 'pregnancy_terminated',\n",
    "        'antenatal_visits',\n",
    "        \n",
    "        # Healthcare access\n",
    "        'distance_health_facility_problem', 'health_insurance',\n",
    "        \n",
    "        # Derived clinical\n",
    "        'age_risk_any', 'high_parity', 'short_birth_interval',\n",
    "        'anemia_severe_moderate', 'bmi_risk', 'adequate_anc',\n",
    "        \n",
    "        # Derived socioeconomic\n",
    "        'healthcare_barriers', 'vulnerability_score',\n",
    "        \n",
    "        # Interactions\n",
    "        'poor_rural', 'poor_uneducated', 'rural_no_insurance',\n",
    "        \n",
    "        # Missing indicators\n",
    "        'birth_interval_months_missing', 'anemia_level_missing'\n",
    "    ],\n",
    "    \n",
    "    # Features with country dummies (for pooled models)\n",
    "    'full_with_country': [\n",
    "        # All full features plus country indicators\n",
    "        'age', 'age_squared', 'residence_type_encoded',\n",
    "        'education_level', 'wealth_index',\n",
    "        'total_children_born', 'birth_interval_months',\n",
    "        'anemia_level', 'bmi', 'pregnancy_terminated',\n",
    "        'antenatal_visits',\n",
    "        'distance_health_facility_problem', 'health_insurance',\n",
    "        'age_risk_any', 'high_parity', 'short_birth_interval',\n",
    "        'anemia_severe_moderate', 'bmi_risk', 'adequate_anc',\n",
    "        'healthcare_barriers', 'vulnerability_score',\n",
    "        'poor_rural', 'poor_uneducated', 'rural_no_insurance',\n",
    "        'birth_interval_months_missing', 'anemia_level_missing',\n",
    "        # Country dummies\n",
    "        'country_GH', 'country_KE', 'country_NG', 'country_TZ', 'country_UG'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Sensitive attributes for fairness analysis\n",
    "SENSITIVE_ATTRIBUTES = [\n",
    "    'wealth_group',      # 5 categories\n",
    "    'wealth_binary',     # Poor vs Non-poor\n",
    "    'residence',         # Urban vs Rural\n",
    "    'education_group',   # 4 categories\n",
    "    'education_binary',  # Secondary+ vs Below\n",
    "    'country'            # 5 countries\n",
    "]\n",
    "\n",
    "print(\"Feature sets defined:\")\n",
    "for name, features in FEATURE_SETS.items():\n",
    "    print(f\"  {name}: {len(features)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all features exist in dataframe\n",
    "print(\"Verifying feature availability:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for set_name, features in FEATURE_SETS.items():\n",
    "    available = [f for f in features if f in df_imputed.columns]\n",
    "    missing = [f for f in features if f not in df_imputed.columns]\n",
    "    \n",
    "    status = \"OK\" if len(missing) == 0 else \"MISSING\"\n",
    "    print(f\"\\n{set_name}: {status}\")\n",
    "    print(f\"  Available: {len(available)}/{len(features)}\")\n",
    "    if missing:\n",
    "        print(f\"  Missing: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## 8. Feature Scaling Preparation\n",
    "\n",
    "Prepare scalers for numeric features. Note: Scaling should be fit on training data only to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which features need scaling\n",
    "numeric_features_to_scale = [\n",
    "    'age', 'age_squared', 'total_children_born', 'birth_interval_months',\n",
    "    'bmi', 'antenatal_visits', 'vulnerability_score', 'healthcare_barriers'\n",
    "]\n",
    "\n",
    "# Features that are already on appropriate scales (binary, ordinal 0-5, etc.)\n",
    "no_scaling_needed = [\n",
    "    'wealth_index', 'education_level', 'anemia_level', 'residence_type_encoded',\n",
    "    'distance_health_facility_problem', 'health_insurance', 'pregnancy_terminated',\n",
    "    'age_risk_any', 'high_parity', 'short_birth_interval', 'anemia_severe_moderate',\n",
    "    'bmi_risk', 'adequate_anc', 'poor_rural', 'poor_uneducated', 'rural_no_insurance',\n",
    "    'birth_interval_months_missing', 'anemia_level_missing'\n",
    "]\n",
    "\n",
    "print(\"Scaling plan:\")\n",
    "print(f\"  To scale: {len(numeric_features_to_scale)} features\")\n",
    "print(f\"  No scaling: {len(no_scaling_needed)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine distributions of numeric features\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_features_to_scale):\n",
    "    if col in df_imputed.columns and i < len(axes):\n",
    "        df_imputed[col].hist(bins=30, ax=axes[i], color='steelblue', edgecolor='white')\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel('')\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Distribution of Features to Scale', y=1.02, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/feature_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## 9. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations for full feature set\n",
    "full_features = [f for f in FEATURE_SETS['full'] if f in df_imputed.columns]\n",
    "corr_matrix = df_imputed[full_features + ['high_risk']].corr()\n",
    "\n",
    "# Plot correlation with target\n",
    "target_corr = corr_matrix['high_risk'].drop('high_risk').sort_values(key=abs, ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "colors = ['indianred' if x > 0 else 'steelblue' for x in target_corr]\n",
    "target_corr.plot(kind='barh', color=colors)\n",
    "plt.xlabel('Correlation with High Risk')\n",
    "plt.title('Feature Correlation with Target Variable')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/figures/feature_target_correlation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for highly correlated features (potential multicollinearity)\n",
    "high_corr_threshold = 0.8\n",
    "\n",
    "# Get upper triangle of correlation matrix\n",
    "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find highly correlated pairs\n",
    "high_corr_pairs = []\n",
    "for col in upper_tri.columns:\n",
    "    for idx in upper_tri.index:\n",
    "        if abs(upper_tri.loc[idx, col]) > high_corr_threshold:\n",
    "            high_corr_pairs.append((idx, col, upper_tri.loc[idx, col]))\n",
    "\n",
    "print(f\"Highly correlated feature pairs (|r| > {high_corr_threshold}):\")\n",
    "print(\"=\" * 60)\n",
    "if high_corr_pairs:\n",
    "    for f1, f2, corr in sorted(high_corr_pairs, key=lambda x: abs(x[2]), reverse=True):\n",
    "        print(f\"  {f1} <-> {f2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"  No highly correlated pairs found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## 10. Summary and Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset summary\n",
    "print(\"FEATURE ENGINEERING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nFinal dataset shape: {df_imputed.shape}\")\n",
    "print(f\"Total samples: {len(df_imputed):,}\")\n",
    "print(f\"Total features: {len(df_imputed.columns)}\")\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  High-risk: {df_imputed['high_risk'].sum():,} ({df_imputed['high_risk'].mean():.1%})\")\n",
    "print(f\"  Low-risk: {(1-df_imputed['high_risk']).sum():,} ({(1-df_imputed['high_risk'].mean()):.1%})\")\n",
    "\n",
    "print(f\"\\nMissing values remaining: {df_imputed.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nFeature sets available:\")\n",
    "for name, features in FEATURE_SETS.items():\n",
    "    available = sum(1 for f in features if f in df_imputed.columns)\n",
    "    print(f\"  {name}: {available} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed dataset\n",
    "output_path = '../data/processed/maternal_health_features.csv'\n",
    "df_imputed.to_csv(output_path, index=False)\n",
    "print(f\"Saved processed data to: {output_path}\")\n",
    "\n",
    "# Save feature set definitions\n",
    "import json\n",
    "feature_sets_path = '../data/processed/feature_sets.json'\n",
    "with open(feature_sets_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'feature_sets': FEATURE_SETS,\n",
    "        'sensitive_attributes': SENSITIVE_ATTRIBUTES,\n",
    "        'numeric_features_to_scale': numeric_features_to_scale,\n",
    "        'target_variable': 'high_risk'\n",
    "    }, f, indent=2)\n",
    "print(f\"Saved feature definitions to: {feature_sets_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature engineering complete!\")\n",
    "print(\"Next: 03_model_training.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
